{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMypD85njCt+3Y9AQ3H8lw0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"rgDalbqipvCH","executionInfo":{"status":"ok","timestamp":1727360275635,"user_tz":-240,"elapsed":587146,"user":{"displayName":"Arabyan Samvel","userId":"00730021639538410996"}},"outputId":"9ee476c8-2bde-4f56-e63d-c7d0605488b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 0.1668\n","Epoch [2/10], Loss: 0.0493\n","Epoch [3/10], Loss: 0.0360\n","Epoch [4/10], Loss: 0.0276\n","Epoch [5/10], Loss: 0.0213\n","Epoch [6/10], Loss: 0.0182\n","Epoch [7/10], Loss: 0.0162\n","Epoch [8/10], Loss: 0.0129\n","Epoch [9/10], Loss: 0.0125\n","Epoch [10/10], Loss: 0.0108\n","Test Accuracy: 98.89%\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","\n","# Define the CNN model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.block1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, padding=2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","        )\n","        self.block2 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","        )\n","        self.fc1 = nn.Linear(in_features=32 * 7 * 7, out_features=120)\n","        self.fc2 = nn.Linear(in_features=120, out_features=84)\n","        self.out = nn.Linear(in_features=84, out_features=10)\n","\n","    def forward(self, x):\n","        x = self.block1(x)\n","        x = self.block2(x)\n","        x = x.view(x.size(0), -1)\n","        x = nn.ReLU()(self.fc1(x))\n","        x = nn.ReLU()(self.fc2(x))\n","        return self.out(x)\n","\n","# Hyperparameters\n","num_epochs = 10\n","batch_size = 64\n","learning_rate = 0.001\n","\n","# Data loading and preprocessing\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","loaders = {\"train\": train_loader, \"test\": test_loader}\n","\n","# Initialize the model, loss function, and optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","cnn = CNN().to(device)\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(cnn.parameters(), lr=learning_rate)\n","\n","# Training loop\n","cnn.train()\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, (images, labels) in enumerate(loaders[\"train\"]):\n","        b_x = Variable(images).to(device)\n","        b_y = Variable(labels).to(device)\n","\n","        output = cnn(b_x)\n","        loss = loss_func(output, b_y)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(loaders[\"train\"]):.4f}')\n","\n","# Evaluation\n","cnn.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in loaders[\"test\"]:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = cnn(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n","\n","# Save the model\n","torch.save(cnn.state_dict(), 'cnn_model.pth')"]}]}